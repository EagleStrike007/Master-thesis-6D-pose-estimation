{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0659b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d446098",
   "metadata": {},
   "source": [
    "# Define camera parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74acddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera intrinsic mattrix\n",
    "camera_matrix = np.array([[606.90486004,   0.        , 326.68717083],\n",
    "                          [  0.        , 608.62302034, 249.21760803],\n",
    "                          [  0.        ,   0.        ,   1.        ]])\n",
    "# Distorsion parameters\n",
    "dist_coeffs = np.array([[ 1.11494374e-01,  5.93164264e-02,  3.38038952e-03,-3.76295683e-05, -1.07614091e+00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16cdec3",
   "metadata": {},
   "source": [
    "# Function to project object mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ply_vtx(pth):\n",
    "    f = open(pth)\n",
    "    assert f.readline().strip() == \"ply\"\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    N = int(f.readline().split()[-1])\n",
    "    while f.readline().strip() != \"end_header\":\n",
    "        continue\n",
    "    pts = []\n",
    "    for _ in range(N):\n",
    "        pts.append(np.float32(f.readline().split()[:3]))\n",
    "    return np.array(pts)\n",
    "\n",
    "def get_model_points():\n",
    "    pointxyz = ply_vtx(r\".\\powerdrill.ply\")\n",
    "    dellist = [j for j in range(0, len(pointxyz))]\n",
    "    dellist = random.sample(dellist, len(pointxyz) - 2000)\n",
    "    pointxyz = np.delete(pointxyz, dellist, axis=0)\n",
    "    return pointxyz\n",
    "\n",
    "def project_p3d(p3d, cam_scale, K):\n",
    "    if type(K) == str:\n",
    "        K = intrinsic_matrix[K]\n",
    "    p3d = p3d * cam_scale\n",
    "    p2d = np.dot(p3d, K.T)\n",
    "    p2d_3 = p2d[:, 2]\n",
    "    p2d_3[np.where(p2d_3 < 1e-8)] = 1.0\n",
    "    p2d[:, 2] = p2d_3\n",
    "    p2d = np.around((p2d[:, :2] / p2d[:, 2:])).astype(np.int32)\n",
    "    return p2d\n",
    "\n",
    "def draw_p2ds(img, p2ds, r=1, color=[(255, 0, 0)]):\n",
    "    if type(color) == tuple:\n",
    "        color = [color]\n",
    "    if len(color) != p2ds.shape[0]:\n",
    "        color = [color[0] for i in range(p2ds.shape[0])]\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    for pt_2d, c in zip(p2ds, color):\n",
    "        pt_2d[0] = np.clip(pt_2d[0], 0, w)\n",
    "        pt_2d[1] = np.clip(pt_2d[1], 0, h)\n",
    "        img = cv2.circle(\n",
    "            img, (pt_2d[0], pt_2d[1]), r, c, -1\n",
    "        )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36619a2c",
   "metadata": {},
   "source": [
    "# Project mask on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "images = glob.glob('path_to_images')\n",
    "\n",
    "# Load annotations, in .json\n",
    "data = [json.loads(line) for line in open('path_to_annotations', 'r')]\n",
    "\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL) \n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "# Loop over all images\n",
    "i = 0\n",
    "for image_file in images:\n",
    "    frame = cv2.imread(image_file)\n",
    "    \n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(frame, aruco_dict, parameters=parameters) \n",
    "    \n",
    "    number = int(os.path.splitext(os.path.split(image_file)[-1])[0])\n",
    "\n",
    "    pose_object = np.array(data[number][\"transformation4x4\"])[0] \n",
    "\n",
    "    mesh_pts = get_model_points().copy()\n",
    "    mesh_pts = np.dot(mesh_pts, pose_object[:3, :3].T) + pose_object[:3, 3]\n",
    "\n",
    "    mesh_p2ds = project_p3d(mesh_pts, 1.0, camera_matrix)\n",
    "\n",
    "    color = (0,0,255)\n",
    "    frame = draw_p2ds(frame, mesh_p2ds, color=color)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    i = i + 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2dc30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "images = glob.glob('path_to_images')\n",
    "\n",
    "# Load annotations, in .json\n",
    "data = [json.loads(line) for line in open('path_to_annotations', 'r')]\n",
    "\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL)\n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "# Loop over all calibration images\n",
    "i = 0\n",
    "rvec, tvec = 0, 0\n",
    "for image_file in images:\n",
    "\n",
    "    frame = cv2.imread(image_file)\n",
    "    \n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    if ids is not None:\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 0.05, camera_matrix, dist_coeffs)\n",
    "\n",
    "        for i in range(len(ids)):\n",
    "            cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvecs[i], tvecs[i], 0.1)\n",
    "\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        aruco_board = cv2.aruco.GridBoard.create(6, 9, 0.05, 0.01, aruco_dict, 0) \n",
    "        _, rvec, tvec = cv2.aruco.estimatePoseBoard(corners, ids, aruco_board, camera_matrix, dist_coeffs, rvec, tvec)\n",
    "        \n",
    "        first_pose = np.eye(4)\n",
    "        first_pose[:3,:3] = cv2.Rodrigues(rvec)[0] \n",
    "        first_pose[:3,3] = tvec[:,0] \n",
    "\n",
    "        cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.3)\n",
    "    \n",
    "    number = int(os.path.splitext(os.path.split(image_file)[-1])[0])\n",
    "\n",
    "    pose_object = np.array(data[number][\"transformation4x4\"])[0] \n",
    "\n",
    "    mesh_pts = get_model_points().copy()\n",
    "    mesh_pts = np.dot(mesh_pts, pose_object[:3, :3].T) + pose_object[:3, 3]\n",
    "\n",
    "    mesh_p2ds = project_p3d(mesh_pts, 1.0, camera_matrix)\n",
    "\n",
    "    color = (0,0,255)\n",
    "    frame = draw_p2ds(frame, mesh_p2ds, color=color)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.waitKey(0)\n",
    "    i = i + 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
