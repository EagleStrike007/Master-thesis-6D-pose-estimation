{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6e12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cb49d",
   "metadata": {},
   "source": [
    "# Define camera parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera intrinsic mattrix\n",
    "camera_matrix = np.array([[606.90486004,   0.        , 326.68717083],\n",
    "                          [  0.        , 608.62302034, 249.21760803],\n",
    "                          [  0.        ,   0.        ,   1.        ]])\n",
    "# Distorsion parameters\n",
    "dist_coeffs = np.array([[ 1.11494374e-01,  5.93164264e-02,  3.38038952e-03,-3.76295683e-05, -1.07614091e+00]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5a286f",
   "metadata": {},
   "source": [
    "# Function to project object mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ply_vtx(pth):\n",
    "    f = open(pth)\n",
    "    assert f.readline().strip() == \"ply\"\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    f.readline()\n",
    "    N = int(f.readline().split()[-1])\n",
    "    while f.readline().strip() != \"end_header\":\n",
    "        continue\n",
    "    pts = []\n",
    "    for _ in range(N):\n",
    "        pts.append(np.float32(f.readline().split()[:3]))\n",
    "    return np.array(pts)\n",
    "\n",
    "def get_model_points():\n",
    "    pointxyz = ply_vtx(r\".\\powerdrill.ply\")\n",
    "    dellist = [j for j in range(0, len(pointxyz))]\n",
    "    dellist = random.sample(dellist, len(pointxyz) - 2000)\n",
    "    pointxyz = np.delete(pointxyz, dellist, axis=0)\n",
    "    return pointxyz\n",
    "\n",
    "def project_p3d(p3d, cam_scale, K):\n",
    "    if type(K) == str:\n",
    "        K = intrinsic_matrix[K]\n",
    "    p3d = p3d * cam_scale\n",
    "    p2d = np.dot(p3d, K.T)\n",
    "    p2d_3 = p2d[:, 2]\n",
    "    p2d_3[np.where(p2d_3 < 1e-8)] = 1.0\n",
    "    p2d[:, 2] = p2d_3\n",
    "    p2d = np.around((p2d[:, :2] / p2d[:, 2:])).astype(np.int32)\n",
    "    return p2d\n",
    "\n",
    "def draw_p2ds(img, p2ds, r=1, color=[(255, 0, 0)]):\n",
    "    if type(color) == tuple:\n",
    "        color = [color]\n",
    "    if len(color) != p2ds.shape[0]:\n",
    "        color = [color[0] for i in range(p2ds.shape[0])]\n",
    "    h, w = img.shape[0], img.shape[1]\n",
    "    for pt_2d, c in zip(p2ds, color):\n",
    "        pt_2d[0] = np.clip(pt_2d[0], 0, w)\n",
    "        pt_2d[1] = np.clip(pt_2d[1], 0, h)\n",
    "        img = cv2.circle(\n",
    "            img, (pt_2d[0], pt_2d[1]), r, c, -1\n",
    "        )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2392c",
   "metadata": {},
   "source": [
    "# First image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70ce10",
   "metadata": {},
   "source": [
    "The first image is processed with the icP algorithm to find the pose of the object relative to the camera. \n",
    "Now the pose of the origin of the markers is caculated relative to the object. \n",
    "\n",
    "The first step is to find the pose of the markers relative to the camera. \n",
    "Then the origin of the markers relative to the object can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the aruco dictionary and detector\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL) \n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "rvec, tvec = 0, 0\n",
    "\n",
    "# Load the image\n",
    "images = glob.glob('path_to_first_image')\n",
    "\n",
    "\n",
    "for image_file in images:\n",
    "    # Load image\n",
    "    frame = cv2.imread(image_file)\n",
    "\n",
    "    # Detect the aruco markers in the frame\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # If any markers are detected\n",
    "    if ids is not None:\n",
    "        # Estimate the pose of each marker\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 0.05, camera_matrix, dist_coeffs)\n",
    "\n",
    "        # Draw the axes of each marker\n",
    "        #for i in range(len(ids)):\n",
    "            #cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvecs[i], tvecs[i], 0.1)\n",
    "\n",
    "        # Draw the IDs of each marker\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        # Estimate the pose of all the markers together\n",
    "        aruco_board = cv2.aruco.GridBoard.create(6, 9, 0.05, 0.01, aruco_dict, 0) \n",
    "        _, rvec, tvec = cv2.aruco.estimatePoseBoard(corners, ids, aruco_board, camera_matrix, dist_coeffs, rvec, tvec)\n",
    "        \n",
    "        # Make transformation matrix\n",
    "        first_pose = np.eye(4)\n",
    "        first_pose[:3,:3] = cv2.Rodrigues(rvec)[0] \n",
    "        first_pose[:3,3] = tvec[:,0] \n",
    "\n",
    "        print(first_pose)\n",
    "        cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.3)\n",
    "              \n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    # Wait until a key is pressed\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Close the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43860cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation (or pose) of hte object relative to the camera\n",
    "pose_object = np.array(  [[-0.96273393,  0.03732234,  0.2678627 , -0.03810231],\n",
    "                          [ 0.22752957,  0.64717135,  0.72759848, -0.04567095],\n",
    "                          [-0.14619739,  0.76143042, -0.63154575,  0.76677086],\n",
    "                          [ 0.        ,  0.        ,  0.        ,  1.        ]])\n",
    "\n",
    "# transformation of the markers relative to the object is calculated \n",
    "pose_markers = np.linalg.inv(first_pose) @ pose_object\n",
    "\n",
    "print(\"pose object to markers:\", pose_markers)\n",
    "\n",
    "print(\"pose object to camera:\", first_pose @ pose_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2165b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualize the first pose\n",
    "mesh_pts = get_model_points().copy()\n",
    "pose_object = first_pose @ pose_markers\n",
    "mesh_pts = np.dot(mesh_pts, pose_object[:3, :3].T) + pose_object[:3, 3]\n",
    "\n",
    "mesh_p2ds = project_p3d(mesh_pts, 1.0, camera_matrix)\n",
    "\n",
    "np_rgb = cv2.imread('./RealSense_images/Pose_2/color/000046.png')\n",
    "color = (255,0,0)\n",
    "np_rgb = draw_p2ds(np_rgb, mesh_p2ds, color=color)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54033dbf",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa4d428",
   "metadata": {},
   "source": [
    "The transformation of the markers relative to the object is calculed. Now the rest of the images are processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ecc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the aruco dictionary and detector\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL) \n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "rvec, tvec = 0, 0\n",
    "# Load the image\n",
    "images = glob.glob('path_to_images')\n",
    "\n",
    "# Loop over all calibration images\n",
    "for image_file in images:\n",
    "    # Load image\n",
    "    frame = cv2.imread(image_file)\n",
    "\n",
    "    # Detect the aruco markers in the frame\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # If any markers are detected\n",
    "    if ids is not None:\n",
    "        # Estimate the pose of each marker\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 0.05, camera_matrix, dist_coeffs)\n",
    "\n",
    "        # Draw the axes of each marker\n",
    "        #for i in range(len(ids)):\n",
    "            #cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvecs[i], tvecs[i], 0.1)\n",
    "\n",
    "        # Draw the IDs of each marker\n",
    "        cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "        # Estimate the pose of all the markers together\n",
    "        aruco_board = cv2.aruco.GridBoard.create(6, 9, 0.05, 0.01, aruco_dict, 0) \n",
    "        _, rvec, tvec = cv2.aruco.estimatePoseBoard(corners, ids, aruco_board, camera_matrix, dist_coeffs, rvec, tvec)\n",
    "        \n",
    "        markers_pose = np.eye(4)\n",
    "        markers_pose[:3,:3] = cv2.Rodrigues(rvec)[0] \n",
    "        markers_pose[:3,3] = tvec[:,0] \n",
    "        \n",
    "        # Draw origin of markers\n",
    "        cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.3)\n",
    "        \n",
    "        # Make transformation matrix\n",
    "        pose_object_to_markers = np.eye(4)\n",
    "        pose_object_to_markers[:3,:3] = cv2.Rodrigues(rvec)[0] \n",
    "        pose_object_to_markers[:3,3] = tvec[:,0] \n",
    "        \n",
    "        # Total pose\n",
    "        total_pose =  pose_object_to_markers @ pose_markers\n",
    "        \n",
    "        # Project mask of 3D object model\n",
    "        mesh_pts = get_model_points().copy()\n",
    "        mesh_pts = np.dot(mesh_pts, total_pose[:3, :3].T) + total_pose[:3, 3]\n",
    "\n",
    "        mesh_p2ds = project_p3d(mesh_pts, 1.0, camera_matrix)\n",
    "        color = (0,0,255)\n",
    "        frame = draw_p2ds(frame, mesh_p2ds, color=color)\n",
    "              \n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    keys = cv2.waitKey(0)\n",
    "    # Exit if the user presses 'q'\n",
    "    if keys == 'q':\n",
    "        break\n",
    "\n",
    "# Close the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811144cc",
   "metadata": {},
   "source": [
    "For saving the annotations, run the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe3d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_transformation( trans, name):\n",
    "    f_out = open( name, 'w')\n",
    "    for i in range(len(trans)):\n",
    "        transform = {\"transformation4x4\": [trans[i].tolist()]}\n",
    "        json.dump( transform, f_out)\n",
    "        f_out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the aruco dictionary and detector\n",
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_ARUCO_ORIGINAL) \n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "rvec, tvec = 0, 0\n",
    "# Load the image\n",
    "images = glob.glob('path_to_images')\n",
    "\n",
    "# Loop over all calibration images\n",
    "for image_file in images:\n",
    "    # Load image\n",
    "    frame = cv2.imread(image_file)\n",
    "\n",
    "    # Detect the aruco markers in the frame\n",
    "    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(frame, aruco_dict, parameters=parameters)\n",
    "\n",
    "    # If any markers are detected\n",
    "    if ids is not None:\n",
    "        # Estimate the pose of each marker\n",
    "        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 0.05, camera_matrix, dist_coeffs)\n",
    "\n",
    "        # Estimate the pose of all the markers together\n",
    "        aruco_board = cv2.aruco.GridBoard.create(6, 9, 0.05, 0.01, aruco_dict, 0) \n",
    "        _, rvec, tvec = cv2.aruco.estimatePoseBoard(corners, ids, aruco_board, camera_matrix, dist_coeffs, rvec, tvec)\n",
    "        \n",
    "        # Make transformation matrix      \n",
    "        pose_object_to_markers = np.eye(4)\n",
    "        pose_object_to_markers[:3,:3] = cv2.Rodrigues(rvec)[0] \n",
    "        pose_object_to_markers[:3,3] = tvec[:,0] \n",
    "        \n",
    "        # Total pose\n",
    "        total_pose =  pose_object_to_markers @ pose_markers\n",
    "              \n",
    "    list_poses.append(total_pose)\n",
    "\n",
    "save_transformation(list_poses, \"transs.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
